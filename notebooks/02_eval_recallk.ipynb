{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5074a5",
   "metadata": {},
   "source": [
    "# Evaluation â€” Recall@k (slice & study)\n",
    "\n",
    "Runs retrieval for a set of phrases and reports Recall@{1,5,10}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8693e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "repo_root = Path.cwd().resolve().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "sys.path.append(str(repo_root / \"src\"))\n",
    "\n",
    "from pgr import encoders, index\n",
    "from pgr.utils import seed_everything, get_device\n",
    "from pgr_dl import io_deeplesion as io, phrases, adapters, eval_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config\n",
    "RESULTS_DIR = repo_root / \"results\" / \"kaggle_v1\"\n",
    "INDEX_PATH  = RESULTS_DIR / \"index.faiss\"\n",
    "IDS_PATH    = RESULTS_DIR / \"ids.parquet\"\n",
    "MODEL_NAME  = \"ViT-B/16\"\n",
    "PHRASE_SET  = [\"liver lesion\",\"renal mass\",\"splenic lesion\",\"lung nodule\",\"enlarged lymph node\",\"bone lesion\"]\n",
    "K_LIST      = [1, 5, 10]\n",
    "K_BUILD     = 100  # retrieve more than you report\n",
    "\n",
    "seed_everything(42)\n",
    "ids_df = pd.read_parquet(IDS_PATH)\n",
    "assert len(ids_df) > 0, \"ids.parquet is empty\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load index + encoder\n",
    "fa = index.FaissIndex.load(str(INDEX_PATH))\n",
    "enc = encoders.ClipEncoder(model_name=MODEL_NAME, device=str(get_device(None)))\n",
    "print(f\"Index ready (dim={fa.dim}), encoder={MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20af2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Slice-level Recall@k\n",
    "rows = []\n",
    "for phrase in PHRASE_SET:\n",
    "    q_vec = adapters.encode_phrase(enc, phrase).cpu().numpy()  # (1,D) float32, L2-normalized\n",
    "    scores, I, _ = fa.search(q_vec, k=K_BUILD)\n",
    "\n",
    "    hits = []\n",
    "    for rk, idx in enumerate(I[0]):\n",
    "        row = ids_df.iloc[int(idx)]\n",
    "        is_pos = phrases.tags_match_phrase(str(row.get(\"body_part\", \"\")),\n",
    "                                            str(row.get(\"lesion_type\", \"\")),\n",
    "                                            phrase)\n",
    "        hits.append({\n",
    "            \"query_phrase\": phrase,\n",
    "            \"rank\": rk + 1,\n",
    "            \"score\": float(scores[0, rk]),\n",
    "            \"study_id\": str(row[\"study_id\"]),\n",
    "            \"slice_idx\": int(row[\"slice_idx\"]),\n",
    "            \"is_positive\": bool(is_pos),\n",
    "        })\n",
    "    res_df = pd.DataFrame(hits)\n",
    "\n",
    "    for k in K_LIST:\n",
    "        r = eval_dl.recall_at_k(res_df, k=k)\n",
    "        rows.append({\"level\": \"slice\", \"phrase\": phrase, \"k\": k, \"recall\": r})\n",
    "\n",
    "slice_table = pd.DataFrame(rows)\n",
    "slice_table.pivot(index=\"phrase\", columns=\"k\", values=\"recall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758450b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Study-level Recall@k\n",
    "study_rows = []\n",
    "for phrase in PHRASE_SET:\n",
    "    q_vec = adapters.encode_phrase(enc, phrase).cpu().numpy()\n",
    "    scores, I, _ = fa.search(q_vec, k=K_BUILD)\n",
    "\n",
    "    hits = []\n",
    "    for rk, idx in enumerate(I[0]):\n",
    "        row = ids_df.iloc[int(idx)]\n",
    "        is_pos = phrases.tags_match_phrase(str(row.get(\"body_part\", \"\")),\n",
    "                                            str(row.get(\"lesion_type\", \"\")),\n",
    "                                            phrase)\n",
    "        hits.append({\n",
    "            \"query_phrase\": phrase,\n",
    "            \"rank\": rk + 1,\n",
    "            \"score\": float(scores[0, rk]),\n",
    "            \"study_id\": str(row[\"study_id\"]),\n",
    "            \"slice_idx\": int(row[\"slice_idx\"]),\n",
    "            \"is_positive\": bool(is_pos),\n",
    "        })\n",
    "    res_df = pd.DataFrame(hits)\n",
    "\n",
    "    # aggregate best slice per study (then recall@k)\n",
    "    best = eval_dl.aggregate_best_slice_per_study(res_df)\n",
    "    for k in K_LIST:\n",
    "        r = eval_dl.recall_at_k(best, k=k)\n",
    "        study_rows.append({\"level\": \"study\", \"phrase\": phrase, \"k\": k, \"recall\": r})\n",
    "\n",
    "study_table = pd.DataFrame(study_rows)\n",
    "study_table.pivot(index=\"phrase\", columns=\"k\", values=\"recall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save metrics table\n",
    "out = (\n",
    "    pd.concat([slice_table, study_table], ignore_index=True)\n",
    "        .sort_values([\"level\", \"phrase\", \"k\"])\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "out_path = RESULTS_DIR / \"recall_table.csv\"\n",
    "out.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n",
    "out\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
