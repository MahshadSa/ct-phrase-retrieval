{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb4fc75",
   "metadata": {},
   "source": [
    "# Build Image Index (DeepLesion Kaggle)\n",
    "\n",
    "This notebook:\n",
    "1) Loads config and metadata  \n",
    "2) Preprocesses CT slices (3-window)  \n",
    "3) Encodes images with CLIP  \n",
    "4) Builds and saves a FAISS index (+ ids parquet)\n",
    "\n",
    "Requires your `src/` modules (`pgr`, `pgr_dl`). Use `pip install -e .` or add repo root to `PYTHONPATH`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36fe956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & setup\n",
    "import sys, json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Add repo root to path if needed\n",
    "repo_root = Path.cwd().resolve().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "sys.path.append(str(repo_root / \"src\"))\n",
    "\n",
    "from pgr import encoders, index\n",
    "from pgr.utils import to_tensor_and_norm, get_device, seed_everything\n",
    "from pgr_dl import io_deeplesion as io, windowing\n",
    "\n",
    "# --- Config (edit paths here or load from YAML) ---\n",
    "CFG = {\n",
    "    \"seed\": 42,\n",
    "    \"paths\": {\n",
    "        \"data_root\": \"/data/deeplesion_kaggle\",   # <<< set your path\n",
    "        \"results_dir\": str(repo_root / \"results\" / \"kaggle_v1\"),\n",
    "    },\n",
    "    \"preprocess\": {\n",
    "        \"input_size\": 224,\n",
    "        \"use_ct3ch\": True,\n",
    "        \"normalize\": \"clip\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"image_encoder\": \"ViT-B/16\",\n",
    "        \"pretrained\": \"openai\",\n",
    "    },\n",
    "    \"index\": {\n",
    "        \"kind\": \"flat\",\n",
    "        \"metric\": \"ip\",\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"split\": \"test\",\n",
    "        \"max_samples\": 5000,          # set None for all\n",
    "    },\n",
    "    \"batch\": 64,\n",
    "}\n",
    "\n",
    "seed_everything(CFG.get(\"seed\", 42))\n",
    "res_dir = Path(CFG[\"paths\"][\"results_dir\"]); res_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Results dir:\", res_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load metadata\n",
    "meta = io.load_metadata(CFG[\"paths\"][\"data_root\"])\n",
    "if CFG[\"data\"][\"split\"]:\n",
    "    meta = meta[meta[\"split\"] == CFG[\"data\"][\"split\"]].copy()\n",
    "if CFG[\"data\"][\"max_samples\"]:\n",
    "    meta = meta.sample(min(int(CFG[\"data\"][\"max_samples\"]), len(meta)),\n",
    "                       random_state=CFG.get(\"seed\", 42)).reset_index(drop=True)\n",
    "\n",
    "print(meta.head(3))\n",
    "print(\"Rows:\", len(meta))\n",
    "if len(meta) == 0:\n",
    "    raise RuntimeError(\"No rows after filteringâ€”check your split/max_samples/settings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Encoder init\n",
    "device = get_device(None)  # auto-pick cuda if available\n",
    "enc = encoders.ClipEncoder(\n",
    "    model_name=CFG[\"model\"][\"image_encoder\"],\n",
    "    pretrained=CFG[\"model\"].get(\"pretrained\", \"openai\"),\n",
    "    device=str(device),\n",
    ")\n",
    "D = enc.embed_dim\n",
    "print(f\"Encoder: {CFG['model']['image_encoder']}  embed_dim={D}  device={device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Embed images (batched)\n",
    "BATCH = int(CFG[\"batch\"])\n",
    "all_vecs = []\n",
    "ids = []\n",
    "size = int(CFG[\"preprocess\"][\"input_size\"])\n",
    "\n",
    "for i in tqdm(range(0, len(meta), BATCH), desc=\"Embedding\"):\n",
    "    batch_df = meta.iloc[i:i+BATCH]\n",
    "    xs = []\n",
    "    for _, r in batch_df.iterrows():\n",
    "        img = io.load_slice(r.img_path)\n",
    "        x3  = windowing.ct3ch(img) if CFG[\"preprocess\"][\"use_ct3ch\"] else img\n",
    "        t   = to_tensor_and_norm(x3, size=size)   # (1,3,H,W)\n",
    "        xs.append(t)\n",
    "        ids.append((str(r.study_id), int(r.slice_idx)))\n",
    "    X = torch.cat(xs, dim=0).to(device, non_blocking=True)  # (B,3,H,W)\n",
    "    V = enc.encode_images(X)                                # (B,D) float32, L2-normed\n",
    "    all_vecs.append(V.cpu().numpy())\n",
    "\n",
    "image_embs = np.vstack(all_vecs).astype(\"float32\")\n",
    "ids_arr = np.array(ids, dtype=object)\n",
    "print(\"Embeddings:\", image_embs.shape, \"IDs:\", ids_arr.shape)\n",
    "assert image_embs.shape[0] == ids_arr.shape[0], \"Row count mismatch\"\n",
    "assert image_embs.shape[1] == D, \"Embedding dim mismatch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Persist embeddings & ids\n",
    "np.save(res_dir / \"image_embs.npy\", image_embs)\n",
    "\n",
    "ids_df = pd.DataFrame(ids_arr, columns=[\"study_id\",\"slice_idx\"])\n",
    "for col in [\"img_path\",\"body_part\",\"lesion_type\"]:\n",
    "    if col in meta.columns:\n",
    "        ids_df[col] = meta[col].values\n",
    "ids_df.to_parquet(res_dir / \"ids.parquet\", index=False)\n",
    "\n",
    "print(\"Saved:\", res_dir / \"image_embs.npy\")\n",
    "print(\"Saved:\", res_dir / \"ids.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build FAISS index\n",
    "fa = index.FaissIndex(\n",
    "    dim=image_embs.shape[1],\n",
    "    kind=CFG.get(\"index\", {}).get(\"kind\", \"flat\"),\n",
    "    metric=CFG.get(\"index\", {}).get(\"metric\", \"ip\"),\n",
    ")\n",
    "fa.add(image_embs)\n",
    "fa.save(res_dir / \"index.faiss\")\n",
    "print(\"Saved:\", res_dir / \"index.faiss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save a small run manifest\n",
    "manifest = {\n",
    "    \"cfg\": CFG,\n",
    "    \"counts\": {\"rows\": int(len(meta)), \"dim\": int(image_embs.shape[1])},\n",
    "    \"paths\": {\n",
    "        \"embeddings\": str(res_dir / \"image_embs.npy\"),\n",
    "        \"ids\": str(res_dir / \"ids.parquet\"),\n",
    "        \"index\": str(res_dir / \"index.faiss\"),\n",
    "    },\n",
    "    \"seed\": int(CFG.get(\"seed\", 42)),\n",
    "}\n",
    "with open(res_dir / \"manifest.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(manifest, f, indent=2, default=str)\n",
    "print(\"Saved:\", res_dir / \"manifest.json\")\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
